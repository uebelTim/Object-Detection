{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 12:02:53.592938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741777373.607581   25295 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741777373.611631   25295 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1741777373.625489   25295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741777373.625511   25295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741777373.625513   25295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741777373.625514   25295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-12 12:02:53.629617: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_voc_dataset(output_dir, dataset_name=\"voc\", dataset_version=\"2007\"):\n",
    "    \"\"\"\n",
    "    Downloads the Pascal VOC object detection dataset using TensorFlow Datasets,\n",
    "    organizes it into train/val/test/all folders, and creates a CSV file with labels.\n",
    "    Uses original image filenames instead of renaming them.\n",
    "    \n",
    "    If the dataset is already downloaded, it will skip the download step.\n",
    "    Also generates VOC-format XML annotation files.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory to save the dataset\n",
    "        dataset_name (str): Dataset name ('voc')\n",
    "        dataset_version (str): Dataset version ('2007' or '2012')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Paths to the organized dataset directories and label CSV\n",
    "    \"\"\"\n",
    "    import xml.etree.ElementTree as ET\n",
    "    from xml.dom import minidom\n",
    "    import time\n",
    "    \n",
    "    # Create output directory structure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir = os.path.join(output_dir, \"val\")\n",
    "    test_dir = os.path.join(output_dir, \"test\")\n",
    "    all_dir = os.path.join(output_dir, \"all\")\n",
    "    \n",
    "    for directory in [train_dir, val_dir, test_dir, all_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        # Create subdirectories for images and annotations\n",
    "        os.makedirs(os.path.join(directory, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(directory, \"annotations\"), exist_ok=True)\n",
    "    \n",
    "    # Define the dataset name with version\n",
    "    full_dataset_name = f\"{dataset_name}/{dataset_version}\"\n",
    "    \n",
    "    # Set a custom download directory to avoid permission issues\n",
    "    temp_data_dir = os.path.join(os.path.expanduser(\"~\"), \"tfds_temp\")\n",
    "    os.makedirs(temp_data_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if the dataset is already downloaded\n",
    "    builder = tfds.builder(full_dataset_name, data_dir=temp_data_dir)\n",
    "    \n",
    "    try:\n",
    "        # Check if dataset info exists, which indicates the dataset is downloaded\n",
    "        if builder.info_path.exists():\n",
    "            print(f\"Dataset {full_dataset_name} already exists, skipping download...\")\n",
    "            download = False\n",
    "        else:\n",
    "            print(f\"Downloading {full_dataset_name} dataset...\")\n",
    "            download = True\n",
    "    except Exception as e:\n",
    "        # If any error occurs during checking, attempt to download\n",
    "        print(f\"Checking dataset status failed ({str(e)}). Attempting to download {full_dataset_name}...\")\n",
    "        download = True\n",
    "    \n",
    "    # Download and prepare the dataset\n",
    "    try:\n",
    "        dataset, info = tfds.load(\n",
    "            name=full_dataset_name,\n",
    "            with_info=True,\n",
    "            split=['train', 'validation', 'test'],\n",
    "            download=download,\n",
    "            data_dir=temp_data_dir\n",
    "        )\n",
    "        print(f\"Dataset loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        print(\"Please check your internet connection and try again.\")\n",
    "        return None\n",
    "    \n",
    "    # Create a list to store label information for CSV\n",
    "    label_data = []\n",
    "    \n",
    "    # VOC class names\n",
    "    class_names = [\n",
    "        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',\n",
    "        'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "    ]\n",
    "    \n",
    "    # Function to create VOC XML annotation file\n",
    "    def create_voc_xml(filename, width, height, objects_list, folder, output_path):\n",
    "        # Create the root element\n",
    "        root = ET.Element(\"annotation\")\n",
    "        \n",
    "        # Add basic elements\n",
    "        ET.SubElement(root, \"folder\").text = folder\n",
    "        ET.SubElement(root, \"filename\").text = filename\n",
    "        ET.SubElement(root, \"path\").text = filename  # Add path element\n",
    "        \n",
    "        # Add size information\n",
    "        size = ET.SubElement(root, \"size\")\n",
    "        ET.SubElement(size, \"width\").text = str(width)\n",
    "        ET.SubElement(size, \"height\").text = str(height)\n",
    "        ET.SubElement(size, \"depth\").text = \"3\"  # Assuming RGB\n",
    "        \n",
    "        # Add segmented (always 0 for object detection)\n",
    "        ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "        \n",
    "        # Add object elements\n",
    "        for obj in objects_list:\n",
    "            object_elem = ET.SubElement(root, \"object\")\n",
    "            ET.SubElement(object_elem, \"name\").text = obj['class_name']\n",
    "            ET.SubElement(object_elem, \"pose\").text = \"Unspecified\"\n",
    "            ET.SubElement(object_elem, \"truncated\").text = \"0\"\n",
    "            ET.SubElement(object_elem, \"difficult\").text = \"0\"\n",
    "            \n",
    "            bbox = ET.SubElement(object_elem, \"bndbox\")\n",
    "            ET.SubElement(bbox, \"xmin\").text = str(obj['xmin'])\n",
    "            ET.SubElement(bbox, \"ymin\").text = str(obj['ymin'])\n",
    "            ET.SubElement(bbox, \"xmax\").text = str(obj['xmax'])\n",
    "            ET.SubElement(bbox, \"ymax\").text = str(obj['ymax'])\n",
    "        \n",
    "        # Create pretty XML string - fix the bytes to string conversion\n",
    "        xml_str = minidom.parseString(ET.tostring(root).decode('utf-8')).toprettyxml(indent=\"  \")\n",
    "        \n",
    "        # Save to file\n",
    "        try:\n",
    "            with open(output_path, \"w\") as f:\n",
    "                f.write(xml_str)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing XML file {output_path}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    # Process each split\n",
    "    split_dirs = {\n",
    "        0: train_dir,  # train\n",
    "        1: val_dir,    # validation\n",
    "        2: test_dir    # test\n",
    "    }\n",
    "    \n",
    "    for split_idx, split_dataset in enumerate(dataset):\n",
    "        split_dir = split_dirs[split_idx]\n",
    "        split_name = ['train', 'validation', 'test'][split_idx]\n",
    "        print(f\"Processing {split_name} split...\")\n",
    "        \n",
    "        # Check if this split has already been processed\n",
    "        split_images_dir = os.path.join(split_dir, \"images\")\n",
    "        split_annot_dir = os.path.join(split_dir, \"annotations\")\n",
    "        existing_images = len(os.listdir(split_images_dir)) if os.path.exists(split_images_dir) else 0\n",
    "        existing_annots = len(os.listdir(split_annot_dir)) if os.path.exists(split_annot_dir) else 0\n",
    "        \n",
    "        if existing_images > 0 and existing_annots > 0:\n",
    "            print(f\"Found {existing_images} existing images and {existing_annots} annotations in {split_name} split. Checking if complete...\")\n",
    "            \n",
    "            # Quick check: count approximate number of examples in this split\n",
    "            sample_count = 0\n",
    "            for _ in split_dataset:\n",
    "                sample_count += 1\n",
    "                if sample_count > 100:  # Just check the first 100 to save time\n",
    "                    break\n",
    "            \n",
    "            if existing_images >= sample_count * 0.9 and existing_annots >= sample_count * 0.9:\n",
    "                print(f\"Split {split_name} appears to be already processed. Skipping...\")\n",
    "                continue\n",
    "        \n",
    "        # Materialize the dataset into a list to avoid streaming it twice\n",
    "        try:\n",
    "            print(f\"Loading {split_name} split data into memory...\")\n",
    "            split_data = list(split_dataset)\n",
    "            print(f\"Loaded {len(split_data)} examples for {split_name} split\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error materializing dataset: {str(e)}\")\n",
    "            print(\"Trying to process streaming instead...\")\n",
    "            split_data = split_dataset\n",
    "        \n",
    "        # Dictionary to keep track of objects for each image, to create XML annotations\n",
    "        image_objects = {}\n",
    "        \n",
    "        # First pass: collect all objects for each image\n",
    "        print(f\"Collecting object information for {split_name} split...\")\n",
    "        start_time = time.time()\n",
    "        for i, example in enumerate(split_data):\n",
    "            if i % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"  Scanning objects for image {i} in {split_name} split ({elapsed:.2f} seconds elapsed)\")\n",
    "            \n",
    "            try:\n",
    "                # Get original filename directly\n",
    "                original_filename = example['image/filename'].numpy().decode('utf-8')\n",
    "                image = example['image'].numpy()\n",
    "                objects = example['objects']\n",
    "                \n",
    "                # Initialize objects list for this image if not already done\n",
    "                if original_filename not in image_objects:\n",
    "                    image_objects[original_filename] = {\n",
    "                        'width': image.shape[1],\n",
    "                        'height': image.shape[0],\n",
    "                        'objects': []\n",
    "                    }\n",
    "                \n",
    "                # Process bounding boxes and labels\n",
    "                if 'bbox' in objects:\n",
    "                    bboxes = objects['bbox'].numpy()  # [ymin, xmin, ymax, xmax] format\n",
    "                    labels = objects['label'].numpy()\n",
    "                    \n",
    "                    # Add each object to the list\n",
    "                    for j, (bbox, label_idx) in enumerate(zip(bboxes, labels)):\n",
    "                        ymin, xmin, ymax, xmax = bbox\n",
    "                        \n",
    "                        # Ensure label_idx is valid\n",
    "                        if label_idx < 0 or label_idx >= len(class_names):\n",
    "                            print(f\"  Warning: Invalid label index {label_idx} for image {original_filename}\")\n",
    "                            continue\n",
    "                            \n",
    "                        class_name = class_names[label_idx]\n",
    "                        \n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        xmin_px = max(0, int(xmin * image.shape[1]))\n",
    "                        ymin_px = max(0, int(ymin * image.shape[0]))\n",
    "                        xmax_px = min(image.shape[1], int(xmax * image.shape[1]))\n",
    "                        ymax_px = min(image.shape[0], int(ymax * image.shape[0]))\n",
    "                        \n",
    "                        # Skip invalid boxes\n",
    "                        if xmin_px >= xmax_px or ymin_px >= ymax_px:\n",
    "                            print(f\"  Warning: Invalid box dimensions for {original_filename}, object {j}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Add to objects list for this image\n",
    "                        image_objects[original_filename]['objects'].append({\n",
    "                            'class_name': class_name,\n",
    "                            'class_id': int(label_idx),\n",
    "                            'xmin': xmin_px,\n",
    "                            'ymin': ymin_px,\n",
    "                            'xmax': xmax_px,\n",
    "                            'ymax': ymax_px\n",
    "                        })\n",
    "                        \n",
    "                        # Add to label data for CSV\n",
    "                        label_data.append({\n",
    "                            'image_filename': original_filename,\n",
    "                            'split': split_name,\n",
    "                            'class_name': class_name,\n",
    "                            'class_id': int(label_idx),\n",
    "                            'xmin': xmin_px,\n",
    "                            'ymin': ymin_px,\n",
    "                            'xmax': xmax_px,\n",
    "                            'ymax': ymax_px,\n",
    "                            'width': image.shape[1],\n",
    "                            'height': image.shape[0]\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing example {i} in {split_name} split: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Second pass: process images and create annotations\n",
    "        processed_images = set()  # Initialize set to keep track of processed images\n",
    "        print(f\"Saving images and creating annotations for {split_name} split...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, example in enumerate(split_data):\n",
    "            if i % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"  Processing image {i} in {split_name} split ({elapsed:.2f} seconds elapsed)\")\n",
    "            \n",
    "            try:\n",
    "                # Extract data\n",
    "                image = example['image'].numpy()\n",
    "                original_filename = example['image/filename'].numpy().decode('utf-8')\n",
    "                \n",
    "                # Skip if already processed this image\n",
    "                if original_filename in processed_images:\n",
    "                    continue\n",
    "                \n",
    "                # Mark as processed\n",
    "                processed_images.add(original_filename)\n",
    "                \n",
    "                # Save image to both split directory and all directory\n",
    "                img_path = os.path.join(split_dir, \"images\", original_filename)\n",
    "                all_img_path = os.path.join(all_dir, \"images\", original_filename)\n",
    "                \n",
    "                if not os.path.exists(img_path) or not os.path.exists(all_img_path):\n",
    "                    try:\n",
    "                        img = Image.fromarray(image)\n",
    "                        img.save(img_path)\n",
    "                        img.save(all_img_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error saving image {original_filename}: {str(e)}\")\n",
    "                \n",
    "                # Create annotation XML files\n",
    "                if original_filename in image_objects:\n",
    "                    # Create filename for annotation (change extension to .xml)\n",
    "                    xml_filename = os.path.splitext(original_filename)[0] + '.xml'\n",
    "                    \n",
    "                    # Paths for both split dir and all dir\n",
    "                    xml_path = os.path.join(split_dir, \"annotations\", xml_filename)\n",
    "                    all_xml_path = os.path.join(all_dir, \"annotations\", xml_filename)\n",
    "                    \n",
    "                    # Only create if doesn't exist\n",
    "                    if not os.path.exists(xml_path):\n",
    "                        create_voc_xml(\n",
    "                            filename=original_filename,\n",
    "                            width=image_objects[original_filename]['width'],\n",
    "                            height=image_objects[original_filename]['height'],\n",
    "                            objects_list=image_objects[original_filename]['objects'],\n",
    "                            folder=split_name,\n",
    "                            output_path=xml_path\n",
    "                        )\n",
    "                    \n",
    "                    if not os.path.exists(all_xml_path):\n",
    "                        create_voc_xml(\n",
    "                            filename=original_filename,\n",
    "                            width=image_objects[original_filename]['width'],\n",
    "                            height=image_objects[original_filename]['height'],\n",
    "                            objects_list=image_objects[original_filename]['objects'],\n",
    "                            folder=\"all\",\n",
    "                            output_path=all_xml_path\n",
    "                        )\n",
    "            except Exception as e:\n",
    "                print(f\"  Error in second pass for image {i} in {split_name} split: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Check if label CSV already exists\n",
    "    csv_path = os.path.join(output_dir, \"voc_labels.csv\")\n",
    "    if os.path.exists(csv_path) and len(label_data) > 0:\n",
    "        print(f\"Label CSV file already exists at: {csv_path}\")\n",
    "        # Optionally, you could append new data or update existing data\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_path)\n",
    "            # Combine existing data with new data\n",
    "            combined_df = pd.concat([existing_df, pd.DataFrame(label_data)]).drop_duplicates()\n",
    "            combined_df.to_csv(csv_path, index=False)\n",
    "            print(f\"Updated existing CSV with new data.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating existing CSV: {str(e)}\")\n",
    "            print(f\"Creating new CSV file...\")\n",
    "            pd.DataFrame(label_data).to_csv(csv_path, index=False)\n",
    "    elif len(label_data) > 0:\n",
    "        # Create new CSV file with all labels\n",
    "        pd.DataFrame(label_data).to_csv(csv_path, index=False)\n",
    "        print(f\"Label CSV file created at: {csv_path}\")\n",
    "    else:\n",
    "        print(\"No label data collected. CSV file not created.\")\n",
    "    \n",
    "    return {\n",
    "        'train_dir': train_dir,\n",
    "        'val_dir': val_dir,\n",
    "        'test_dir': test_dir,\n",
    "        'all_dir': all_dir,\n",
    "        'labels_csv': csv_path if os.path.exists(csv_path) else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC dataset saved to: {'train_dir': 'Data/voc2007/train', 'val_dir': 'Data/voc2007/val', 'test_dir': 'Data/voc2007/test', 'all_dir': 'Data/voc2007/all', 'labels_csv': 'Data/voc2007/voc_labels.csv'}\n",
      "\n",
      "Dataset organization complete!\n",
      "Train directory: Data/voc2007/train\n",
      "Validation directory: Data/voc2007/val\n",
      "Test directory: Data/voc2007/test\n",
      "All data directory: Data/voc2007/all\n",
      "Labels CSV file: Data/voc2007/voc_labels.csv\n",
      "\n",
      "Total objects: 30638\n",
      "Total images: 9963\n",
      "\n",
      "Class distribution:\n",
      "class_name\n",
      "person         10674\n",
      "car             3185\n",
      "chair           2806\n",
      "bottle          1291\n",
      "pottedplant     1217\n",
      "bird            1175\n",
      "dog             1068\n",
      "sofa             821\n",
      "bicycle          807\n",
      "horse            801\n",
      "boat             791\n",
      "cat              759\n",
      "motorbike        759\n",
      "tvmonitor        728\n",
      "cow              685\n",
      "sheep            664\n",
      "aeroplane        642\n",
      "train            630\n",
      "diningtable      609\n",
      "bus              526\n",
      "Name: count, dtype: int64\n",
      "num classes 20\n"
     ]
    }
   ],
   "source": [
    "#output_paths = download_voc_dataset(output_dir=\"Data/voc2007\", dataset_version=\"2007\")\n",
    "print(f\"VOC dataset saved to: {output_paths}\")\n",
    "print(\"\\nDataset organization complete!\")\n",
    "print(f\"Train directory: {output_paths['train_dir']}\")\n",
    "print(f\"Validation directory: {output_paths['val_dir']}\")\n",
    "print(f\"Test directory: {output_paths['test_dir']}\")\n",
    "print(f\"All data directory: {output_paths['all_dir']}\")\n",
    "print(f\"Labels CSV file: {output_paths['labels_csv']}\")\n",
    "\n",
    "# Print CSV stats\n",
    "df = pd.read_csv(output_paths['labels_csv'])\n",
    "print(f\"\\nTotal objects: {len(df)}\")\n",
    "print(f\"Total images: {df['image_filename'].nunique()}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['class_name'].value_counts())\n",
    "print('num classes',len(df['class_name'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
