{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "#from keras_cv import visualizations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'C:\\Users\\ue\\OneDrive - IMS Messsysteme GmbH\\Uni\\MasterArbeit\\Data\\Batch1\\Batch_1'\n",
    "labels_path = r'C:\\Users\\ue\\OneDrive - IMS Messsysteme GmbH\\Uni\\MasterArbeit\\Data\\Batch1\\Batch_1_Labels_BBs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 12:09:46.899494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741864186.914315   27630 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741864186.918397   27630 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 12:09:46.932867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m\n\u001b[1;32m    102\u001b[0m     val_ds \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mcache()\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_ds, val_ds, class_mapping\n\u001b[0;32m--> 107\u001b[0m train_ds, val_ds, class_mapping \u001b[38;5;241m=\u001b[39m build_image_detection_pieline()\n",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m, in \u001b[0;36mbuild_image_detection_pieline\u001b[0;34m(img_size, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdict_to_tuple\u001b[39m(inputs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m], inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_boxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(img_path))\n\u001b[1;32m     57\u001b[0m files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_path, file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[1;32m     58\u001b[0m label_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(labels_path))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def build_image_detection_pieline(img_size=(128,128), batch_size=32):\n",
    "    classes = ['class_0','class_A','class_B','class_C','class_D','class_E','class_F']\n",
    "    class_mapping = dict(zip(range(len(classes)), classes))\n",
    "    \n",
    "    def parse_labels(label_path):\n",
    "        #read label file without tf\n",
    "        label = open(label_path, 'r').read().split('\\n')\n",
    "        \n",
    "        class_ids = []\n",
    "        bbs = []\n",
    "        for line in label:\n",
    "            if line == '':\n",
    "                continue\n",
    "            #first string before space is the class, after that is the bounding box\n",
    "            class_name = tf.strings.split(line, sep=' ')[0]\n",
    "            class_id = classes.index(class_name)\n",
    "            #read bounding box without tf\n",
    "            bb = line.split(' ')[1:]\n",
    "            bb = [float(i) for i in bb]\n",
    "            #clip values to 0 and 1\n",
    "            bb = [max(0,i) for i in bb]\n",
    "            bb = [min(1,i) for i in bb]\n",
    "            x1 = bb[0]*img_size[0]\n",
    "            y1 = bb[1]*img_size[1]\n",
    "            x2 = bb[2]*img_size[0]\n",
    "            y2 = bb[3]*img_size[1]\n",
    "            #print([x1,y1,x2,y2])\n",
    "            class_ids.append(class_id)\n",
    "            bbs.append([x1,y1,x2,y2])\n",
    "            \n",
    "            #class_name = tf.strings.to_number(class_name)\n",
    "            \n",
    "        return class_ids, bbs\n",
    "    \n",
    "    def parse_images(image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_png(image, channels=1) \n",
    "        image = tf.image.resize(image, img_size)\n",
    "        return image\n",
    "    \n",
    "    def load_dataset(img_files,id,bb):\n",
    "        image = parse_images(img_files)\n",
    "        bounding_boxes = {\n",
    "            \"classes\": tf.cast(id, dtype=tf.int64),\n",
    "            \"boxes\": bb,\n",
    "                        }\n",
    "        return {\"images\": tf.cast(image, tf.int64), \"bounding_boxes\": bounding_boxes}\n",
    "   \n",
    "    \n",
    "    def dict_to_tuple(inputs):\n",
    "        return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "    \n",
    "    files = sorted(os.listdir(img_path))\n",
    "    files = [os.path.join(img_path, file) for file in files]\n",
    "    label_files = sorted(os.listdir(labels_path))\n",
    "    label_files = [os.path.join(labels_path, label) for label in label_files]\n",
    "    class_ids = []\n",
    "    bbs = []\n",
    "    for label in tqdm(label_files):\n",
    "        class_id, bb = parse_labels(label)\n",
    "        class_ids.append(class_id)\n",
    "        bbs.append(bb)\n",
    "    class_ids = tf.ragged.constant(class_ids)\n",
    "    bbs = tf.ragged.constant(bbs)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((files,class_ids,bbs))\n",
    "    dataset = dataset.shuffle(len(files))\n",
    "\n",
    "    train_size = int(0.7 * len(files))\n",
    "    val_size = int(0.3 * len(files))\n",
    "    train_ds = dataset.take(train_size)\n",
    "    val_ds = dataset.skip(train_size)\n",
    "    \n",
    "    augmentor = keras.Sequential(\n",
    "        layers=[\n",
    "            #keras_cv.layers.Resizing(128,128, bounding_box_format=\"xyxy\"),\n",
    "            keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xyxy\"),\n",
    "            keras_cv.layers.RandomShear(x_factor=0.1, y_factor=0.1, bounding_box_format=\"xyxy\"),\n",
    "            keras_cv.layers.JitteredResize(\n",
    "                target_size=(128,128), scale_factor=(0.75, 1.3), bounding_box_format=\"xyxy\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    resizing = keras_cv.layers.JitteredResize(\n",
    "        target_size=(128,128),\n",
    "        scale_factor=(0.75, 1.3),\n",
    "        bounding_box_format=\"xyxy\",\n",
    "    )\n",
    "    \n",
    "    train_ds = train_ds.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.ragged_batch(batch_size, drop_remainder=True)\n",
    "    train_ds = train_ds.map(augmentor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = val_ds.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.ragged_batch(batch_size, drop_remainder=True)\n",
    "    val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    \n",
    "    return train_ds, val_ds, class_mapping\n",
    "\n",
    "train_ds, val_ds, class_mapping = build_image_detection_pieline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#visualize images and bounding boxes in train_ds\n",
    "inputs = next(iter(train_ds.take(1)))\n",
    "image = inputs[0]\n",
    "bounding_boxes = inputs[1]\n",
    "bounding_boxes = bounding_boxes['boxes']\n",
    "bounding_boxes = bounding_boxes.numpy()\n",
    "bounding_boxes = bounding_boxes[0]\n",
    "\n",
    "window = cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 600,600)\n",
    "cv2.imshow('image', image[0])\n",
    "#draw bounding boxes\n",
    "for bb in bounding_boxes:\n",
    "    bb = bb.numpy()\n",
    "    bb = bb.astype(int)\n",
    "    image = cv2.rectangle(image[0], (bb[0],bb[1]), (bb[2],bb[3]), (255,255,255), 2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['class_0','class_A','class_B','class_C','class_D','class_E','class_F']\n",
    "class_mapping = dict(zip(range(len(classes)), classes))\n",
    "print(class_mapping)\n",
    "ids=list(class_mapping.keys())[list(class_mapping.values()).index('class_E')]\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['class_0','class_A','class_B','class_C','class_D','class_E','class_F']\n",
    "id = classes.index('class_E')\n",
    "print(id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
